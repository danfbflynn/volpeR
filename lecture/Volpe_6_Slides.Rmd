---
title: 'Volpe R Course: Session 6, Expanded Statistical Toolbox'
author: "| Instructors: Don Fisher, Dan Flynn, Jessie Yang \n| Course webpage: http://bit.ly/volpeR\n"
date: "5/25/2017"
output:
  slidy_presentation: default
  beamer_presentation:
    includes:
      in_header: beamertemp.tex
    incremental: no
fontsize: 8pt
colortheme: dolphin
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.height = 3.5)
setwd("C:/Users/daniel.flynn.ctr/Documents/git/volpeR/lecture")
```


## Overview 

### Last session: Data manipulation

- Merging data frames
- Basic manipulations
- Plotting spatial data

### This session:

#### Expanded Statistical Toolbox

- Hierarchical modeling
- Repeated measures and time series

#### Project Presentations

## Expanded Statitcal Toolbox

We will work with two data files, on the course Google Drive, <http://bit.ly/volpeR>:
- `US_State_Avg_Ann_Temp.csv`
- `Net_generation_for_all_fuels_(utility-scale)_monthly.csv`

Download them and read them in. For the Fuel generation file, downloaded from the Energy Information Administration, we need to skip several lines at the top:

```{r}
avg.temp <- read.csv("data/US_State_Avg_Ann_Temp.csv")
net.fuel <- 
  read.csv("data/Net_generation_for_all_fuels_(utility-scale)_monthly.csv",
                     skip = 4)

```

The fuel data also needs some cleaning up with the file names, which we can do using `sub`:

```{r, results = 'hide'}
names(net.fuel)
names(net.fuel) <- sub("...all.sectors.thousand.megawatthours", # Pattern 
                       "",                                      # Replacement
                       names(net.fuel))                         # Vector 
names(net.fuel)
```

## Merging data frames

Using the example data, let's reshape and merge the data together.

```{r, results = 'hide'}
library(reshape)
net.melt <- melt(net.fuel)
names(net.melt) = c("Month", "Region", "NetFuel")

avg.temp$Region <- gsub(" ", ".", avg.temp$Region) 
# gsub matches multiple instances

fuel.temp <- merge(avg.temp, net.melt, all.y = T)
```

## Merging data for spatial analysis

One application of the merge data is to plot it spatially. 

```{r, results = 'hide', eval = F}
library(maps)
map('state') 
# Plot avg temp 
statenames  <- map('state', plot = FALSE)$names
statematches <- match(statenames, tolower(avg.temp$State))
tempmatches <- avg.temp$Avg.degF[statematches]

colorpal <- heat.colors(100)

temp.colors <- colorpal[round(tempmatches)]

map('state', 
    col = temp.colors,
    fill = T)
```

## Hierarchical modeling

http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf
https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf

Hierarchical models are also called *mixed-effects models*, because they mix *fixed* and *random* effects.

- **Fixed effects** are typically predictors you are most interested in. If these are categorical, these are variables usually only have a few different levels, all of which are represented in you data (*all of few*). An example would be two levels of an experimental treatment.
- **Random effects** are predictors which may be very important, but which you would like to generalize across. Usually categorical, and you may only have a few of many possible levels in your data (*few of many*). An example would be several States.

In hierarchical modeling, you essentially analyze your fixed effects within each level of the random effects, then pool your results across all the random effects.

## Hierarchical modeling

Here is an example, looking at our fuel consumption data by region.
```{r}
library(lme4) # install.packages(lme4) 

```

## Hierarchical modeling


```{r}
# Modeling by state and month
head(fuel.temp)

# State-level trends

library(lme4)



```

## Repeated measures modeling

We can use the hierarchical modeling framework to look at repeated measures or time series. 

Example: subjects are deprived of sleep and are measureed for their reaction times at increasing intervals  (see `?sleepstudy`). How much does sleep deprivation matter?
We want to track each subject seperately, then pool the results to come up with general conclusions.
```{r, results = 'hide'}
rm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
summary(rm1)
fixef(rm1); ranef(rm1)
```
Each additional day increases reaction time by 10.5 +/- 1.5 ms. 

You may be asking yourself, "but what about my p-values?". This is a normal reaction when encountering mixed-effects models! One solution:
```{r}
library(sjPlot) # install.packages(sjPlot) first
sjt.lmer(rm1)
```


## Saving your work

After doing all this work, you will want to save the results. You can save R objects in your current workspace to file type called `.RData`. Then you can load these R objects back in at a later session, without having to carry out this preparation work.

For example, to save all objects in the current workspace:

`save(list = ls(), file = "My_Prepped_Data.RData")`

and load it back in using

`load("My_Prepped_Data.RData")`

To save specific R objects, you will name them in the list as strings, such as

`save(list = c('fuel.temp', 'avg.temp'), file = "My_Prepped_Data.RData")`

You can also consider making a script that does all this preparation work, and save it as a file called something like `Analysis Prep.R`. Then, in your data analysis script or `.Rmd` file, you can automatically run that script by inserting the command:
`source('Analysis Prep.R')`.

## Report Presentation

Show the report you generated for this session (using `.Rmd`) and explain the story it tells. Show them how you used Markdown in your case, and get their feedback on elements to edit or improve. Leave enough time for both people to present.

